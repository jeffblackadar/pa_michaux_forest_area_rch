{"cells":[{"cell_type":"markdown","metadata":{"id":"irj2I2XBAQdg"},"source":["# Read the predictions from the annot xml files and convert them into GIS shapefiles"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31113,"status":"ok","timestamp":1649782008339,"user":{"displayName":"Jeff Blackadar","userId":"06863186953991085499"},"user_tz":240},"id":"Oy7ZoaUibOGF","outputId":"4effc760-9c1a-4da7-c7f4-1102299056b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# cell 1\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MmhL42tDibbC"},"outputs":[],"source":["# cell 2\n","!pip install geopandas"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dEca295aAQds","executionInfo":{"status":"ok","timestamp":1649782904819,"user_tz":240,"elapsed":149,"user":{"displayName":"Jeff Blackadar","userId":"06863186953991085499"}}},"outputs":[],"source":["# cell 3 - Run this load these functions\n","def get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,x,y):\n","    # supposing x and y are your pixel coordinate this \n","    # is how to get the coordinate in space.\n","    posX = px_w * x + rot1 * y + xoffset\n","    posY = rot2 * x + px_h * y + yoffset\n","\n","    # shift to the center of the pixel\n","    posX += px_w / 2.0\n","    posY += px_h / 2.0\n","    return posX,posY\n","\n","def get_poly_from_geotif_with_x_y(geotif_fp,minx,miny,maxx,maxy):\n","    ds = gdal.Open(geotif_fp)\n","    # open the dataset and get the geo transform matrix\n","\n","    xoffset, px_w, rot1, yoffset, rot2,px_h = ds.GetGeoTransform()\n","\n","    #print(\"xoffset, px_w, rot1, yoffset, px_h, rot2\",xoffset, px_w, rot1, yoffset, px_h, rot2)\n","    #print(\"minx,miny,maxx,maxy\",minx,miny,maxx,maxy)\n","\n","    pos1x,pos1y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,miny)\n","    pos2x,pos2y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,maxy)\n","    pos3x,pos3y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,maxy)\n","    pos4x,pos4y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,miny)\n","    coords = [(pos1x,pos1y), (pos2x,pos2y), (pos3x,pos3y), (pos4x,pos4y)]\n","\n","    #print(\"pos\",pos1x,pos1y,pos2x,pos2y,pos3x,pos3y,pos4x,pos4y)\n","    poly = Polygon(coords)\n","    \n","    return poly "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kfwz3_jAQdv"},"outputs":[],"source":["# cell 4 - Run this to load a dictionary of files to process\n","# Looping through them repeatedly takes a long time.\n","# Instead, create a dictionary of files indexed by area. Each entry holds a list of matching files\n","# This makes it easier to process these files by area.\n","batch_group = '0-597'\n","\n","import csv\n","import os\n","from os import listdir\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","\n","#make a dict of all the areas + pan (or pas)\n","area_crs_dict = {}\n","area_crs_dict[\"pa_forest_district_01_michaux\"] = []\n","\n","# Now that the dictionary is created, add all of the matching files as a list linked to the entry.\n","# This dictionary will be used below.\n","\n","annot_prediction_folder = os.path.join('/content/drive/MyDrive/crane_pennsylvania/predictions/project_pa_district_01_michaux/cfg20200826T2315/unknown/'+batch_group+'/')\n","\n","for annot_filename in listdir(annot_prediction_folder):\n","    annot_area = \"pa_forest_district_01_michaux\"\n","    print(annot_filename, annot_area)\n","    area_node = area_crs_dict[annot_area]\n","    area_node.append(annot_filename)\n","print(area_crs_dict) "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"c4uUVab3AQdw","executionInfo":{"status":"ok","timestamp":1649782915748,"user_tz":240,"elapsed":2087,"user":{"displayName":"Jeff Blackadar","userId":"06863186953991085499"}}},"outputs":[],"source":["# cell 5\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","model_epoch='0016'\n","\n","split_tifs_folder = '/content/drive/MyDrive/crane_pennsylvania/lidar_files/slope/slope_'+ batch_group +'/'\n","# display image with masks and bounding boxes\n","\n","from xml.etree import ElementTree\n","#https://gis.stackexchange.com/questions/92207/split-a-large-geotiff-into-smaller-regions-with-python-and-gdal\n","import os\n","from os import listdir\n","import numpy\n","from osgeo import gdal, osr\n","import math\n","from itertools import chain\n","import geopandas as gpd\n","from shapely.geometry import Point, Polygon\n","import numpy as np\n","import gdalnumeric\n","\n","import cv2\n","def put_preds_in_shp(state_area,state_area_num_crs):\n","\n","    pred_polys = gpd.GeoDataFrame()\n","    pred_polys['geometry'] = None\n","    \n","    pred_polys.crs = (\"EPSG:\" + str(state_area_num_crs))    \n","    #pred_polys.geometry = pred_polys.geometry.crs(epsg=state_area_num_crs)\n","    pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","    print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)    \n","\n","    #Store the results in XML    \n","    class_names = construction_type\n","\n","    # find all images\n","    pa = area_crs_dict[str(state_area)]\n","    for annot_filename in pa:\n","    \n","        #print(annot_filename)\n","        #process only the files for this state land area, since other areas may not match crs\n","        #if annot_filename.startswith(state_area_num):\n","        tree = ElementTree.parse(annot_prediction_folder+annot_filename)\n","        print(annot_prediction_folder+annot_filename)\n","        #print(tree)\n","        # get the root of the document\n","        root = tree.getroot()\n","        # extract each bounding box\n","    \n","        fn_image = root.find('./filename').text\n","        #object_present = root.find('./object_present').text\n","        fn_base = fn_image[:-4]\n","        #print(fn_base)\n","        box_num=0\n","        for obj in root.findall('./object'):\n","            score = obj.find('score').text\n","    \n","            box = obj.find('bndbox')\n","            box_num=obj.find('number').text\n","            box_num_pad = \"00\"+str(box_num)\n","            box_num_pad = box_num_pad[-2:]\n","            xmin = int(box.find('xmin').text)\n","            ymin = int(box.find('ymin').text)\n","            xmax = int(box.find('xmax').text)\n","            ymax = int(box.find('ymax').text)\n","            if(ymin>ymax):\n","                ytemp = ymin\n","                ymin = ymax\n","                ymax=ytemp\n","            if(xmin>xmax):\n","                xtemp = xmin\n","                xmin = xmax\n","                xmax=xtemp            \n","            coors = [xmin, ymin, xmax, ymax]\n","            #print(\"score\", score, coors)\n","            print(os.path.join(split_tifs_folder+(fn_base+\".tif\")))\n","            try:\n","                pred_poly = get_poly_from_geotif_with_x_y(os.path.join(split_tifs_folder+(fn_base+\".tif\")),xmin,ymin,xmax,ymax)\n","                new_pp_row = {'id':fn_base+box_num_pad, 'geometry':pred_poly, 'score':score}\n","                pred_polys = pred_polys.append(new_pp_row, ignore_index=True)\n","            except:\n","                print(\"ERROR with file above ^\")\n","            #print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","            pred_polys.geometry.crs = (\"EPSG:\" + str(state_area_num_crs))\n","            #print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","\n","\n","    outfolder = os.path.join(\"/content/drive/MyDrive/crane_pennsylvania/predictions/project_pa_district_01_michaux/\", (cfg_name+\"/\"), \"polys/\", (batch_group+'/'))\n","    if not os.path.exists(outfolder):\n","        os.makedirs(outfolder)\n","    outfp = os.path.join(outfolder,(state_area + \"_predictions.shp\"))\n","                         \n","# Write the data into that Shapefile\n","    if not pred_polys.empty:\n","        #pred_polys.head()\n","        #pred_polys = pred_polys.to_crs({'init':'epsg:4326'})\n","        #pred_polys = pred_polys.to_crs(epsg = 26918)\n","        print(\"pred_polys.crs\",pred_polys.crs, pred_polys.geometry.crs)\n","        pred_polys.to_file(outfp)\n","        print(\"File written to\", outfp)\n","\n","        \"\"\"\n","        crs_4326 = 4326\n","        pred_polys.geometry = pred_polys.geometry.to_crs(crs=crs_4326)\n","        pred_polys.to_crs(crs=crs_4326)\n","        pred_polys = pred_polys.to_crs(epsg=crs_4326)\n","        \n","        #pred_polys = pred_polys.set_crs(epsg = 4326)\n","        #pred_polys.head()\n","        outfp = os.path.join(outfolder,(\"4326_\" + state_area + \"_predictions.shp\"))\n","        # Write the data into that Shapefile\n","        pred_polys.to_file(outfp)\n","        \"\"\"\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L32ZeNU6AQdy"},"outputs":[],"source":["# cell 6\n","put_preds_in_shp(\"pa_forest_district_01_michaux\",26918)"]},{"cell_type":"code","source":["geotif_fp = '/content/drive/MyDrive/crane_pennsylvania/lidar_files/slope/slope_0-597/slope_15001970pas10_utm.tif'\n","minx = 294\n","miny = 1478\n","maxx = 337\n","maxy = 1521\n","\n","# pos 197092.296875 4381544.0 197092.296875 4381501.0 197135.296875 4381501.0 197135.296875 4381544.0\n","\n","\n","ds = gdal.Open(geotif_fp)\n","print(ds.GetProjection())\n","# open the dataset and get the geo transform matrix\n","\n","xoffset, px_w, rot1, yoffset, rot2,px_h = ds.GetGeoTransform()\n","\n","#print(\"xoffset, px_w, rot1, yoffset, px_h, rot2\",xoffset, px_w, rot1, yoffset, px_h, rot2)\n","print(\"minx,miny,maxx,maxy\",minx,miny,maxx,maxy)\n","\n","pos1x,pos1y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,miny)\n","pos2x,pos2y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,minx,maxy)\n","pos3x,pos3y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,maxy)\n","pos4x,pos4y = get_posx_posy(xoffset, px_w, rot1, yoffset, px_h, rot2,maxx,miny)\n","coords = [(pos1x,pos1y), (pos2x,pos2y), (pos3x,pos3y), (pos4x,pos4y)]\n","\n","print(\"pos\",pos1x,pos1y,pos2x,pos2y,pos3x,pos3y,pos4x,pos4y)\n","poly = Polygon(coords)"],"metadata":{"id":"h0RkwdefE4c1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVxA6t-RAQdz"},"source":["# Convert Polygons to Points and remove Duplicates\n","For each area, load the polygons.\n","Check if any existing points from previous areas processed are inside any of the polygons of this area.\n","If there are \"matches\" (duplicates), the polygons are removed (and stored in a dataframe of duplicates)\n","The left over unique polygons are then processed for their centroids.\n","These points are stored for output and also used to process the polygons for the remaining areas so see if there are duplicates for in the polygons of the remaining areas."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4120,"status":"ok","timestamp":1649786191347,"user":{"displayName":"Jeff Blackadar","userId":"06863186953991085499"},"user_tz":240},"id":"7vGTsJWOAQd0","outputId":"817ea59c-8b0a-4934-a84f-1fd9135567de"},"outputs":[{"output_type":"stream","name":"stdout","text":["0-597\n","pa_forest_district_01_michaux\n","/content/drive/MyDrive/crane_pennsylvania/predictions/project_pa_district_01_michaux/cfg20200826T2315/polys/0-597/pa_forest_district_01_michaux_predictions.shp\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: FutureWarning: Assigning CRS to a GeoDataFrame without a geometry column is now deprecated and will not be supported in the future.\n"]},{"output_type":"stream","name":"stdout","text":["Total points area: 2958  Total duplicates: 0\n","Total points for area: 2958\n","Total points: 2958\n"]}],"source":["import geopandas as gpd\n","import pandas as pd\n","import numpy as np\n","import os\n","import csv\n","def preds_to_points(area, pred_poly_folder, all_pred_points_df, dup_pred_polys_df, area_crs = 26918):\n","    # print(all_pred_points_df.shape)\n","    print(area)\n","    area_pred_polys_path = os.path.join(pred_poly_folder,(area + \"_predictions.shp\"))\n","    print(area_pred_polys_path)\n","    if os.path.exists(area_pred_polys_path):\n","        area_pred_polys = gpd.read_file(area_pred_polys_path)\n","        # selection = pred_data[0:]\n","        # print(list(area_pred_polys))\n","        # print(area_pred_polys.shape)\n","\n","        matched_pred_polys = list()    \n","        area_pred_polys.to_crs(area_crs)\n","        # for pred_poly in area_pred_polys:\n","        for index, row in area_pred_polys.iterrows():\n","            #print(\"row\",row[0],row[1],row[2])\n","            pred_poly = row[2]\n","            # any_points = all_pred_points_df.within(pred_poly.loc[0, 'geometry'])\n","            any_points = all_pred_points_df.within(pred_poly)\n","            #print(\"any_points\",any_points)\n","            if(any(any_points) == True):\n","                # print(\"MATCHES\")\n","                matched_pred_polys.append(str(row[0]))\n","                \n","        # print(matched_pred_polys)\n","        # If there is more than 0 matches, remove them from the dataframe\n","        if(len(matched_pred_polys) > 0 ):\n","            print(\"area_pred_polys len before \",len(area_pred_polys))\n","            for mpp in matched_pred_polys:\n","                index_matches = area_pred_polys[area_pred_polys['id'] == mpp].index\n","                #dup_row = area_pred_polys.loc([area_pred_polys['id'] == mpp]\n","                # get the duplicate row\n","                dup_row = area_pred_polys.loc[area_pred_polys['id'] == mpp]\n","                #print(\"dup_row....\",dup_row,dup_row['id'])\n","                #print(\"index_matches\",index_matches)\n","                #print(\"dup_pred_polys_df len before\",len(dup_pred_polys_df))\n","                # put the duplicate row into a dataframe it can be saved to check it.\n","                dup_pred_polys_df = dup_pred_polys_df.append(dup_row, ignore_index=True)\n","                #print(\"dup_pred_polys_df len after\",len(dup_pred_polys_df))\n","                area_pred_polys.drop(index_matches, inplace = True)\n","            # area_pred_polys.drop(matched_pred_polys)\n","            print(\"area_pred_polys len after \",len(area_pred_polys))\n","            \n","        # Create an empty geopandas GeoDataFrame\n","        area_pred_points_df = gpd.GeoDataFrame()\n","        #area_pred_points_df.crs = {'init':'epsg:' + str(area_crs)}\n","        area_pred_points_df.crs = ('EPSG:' + str(area_crs))\n","        \n","        area_pred_points_df['geometry'] = area_pred_polys.centroid\n","        # make an id\n","        id_list = np.arange(1,len(area_pred_polys.centroid)+1)\n","        # print(id_list)\n","        id_list = [(area + \"-\" + ((\"000\"+str(i))[-4:])) for i in id_list]\n","        # print(id_list)\n","        area_pred_points_df['id'] = id_list\n","        area_pred_points_df['score'] = area_pred_polys['score']\n","        \n","        dataframesList = [all_pred_points_df, area_pred_points_df]\n","        all_pred_points_df = gpd.GeoDataFrame(pd.concat(dataframesList, ignore_index=True), crs=dataframesList[0].crs)\n","        \n","        print(\"Total points area:\", len(all_pred_points_df),\" Total duplicates:\", len(dup_pred_polys_df))\n","        return all_pred_points_df, dup_pred_polys_df, area_pred_points_df\n","    else:\n","        print(\"Total points area:\", len(all_pred_points_df),\" Total duplicates:\", len(dup_pred_polys_df))\n","        return all_pred_points_df, dup_pred_polys_df, area_pred_points_df\n","\n","\n","construction_type = \"charcoal_hearth_hill\"\n","cfg_name = 'cfg20200826T2315'\n","area_crs = 26918\n","area_name = \"pa_forest_district_01_michaux\"\n","\n","# Create an empty geopandas GeoDataFrame\n","all_pred_points_df = gpd.GeoDataFrame()\n","all_pred_points_df['geometry'] = None\n","all_pred_points_df['id'] = None\n","all_pred_points_df.crs = ('EPSG:'+str(area_crs))\n","\n","# Create an empty geopandas GeoDataFrame for duplicates\n","dup_pred_polys_df = gpd.GeoDataFrame()\n","dup_pred_polys_df['geometry'] = None\n","dup_pred_polys_df['id'] = None\n","dup_pred_polys_df.crs = ('EPSG:'+str(area_crs))\n","\n","poly_folder = \"/content/drive/MyDrive/crane_pennsylvania/predictions/project_pa_district_01_michaux/cfg20200826T2315/polys/\"\n","all_points_outfp = os.path.join(poly_folder, (area_name+\"_all_hearth_prediction_points.shp\"))\n","dup_polys_outfp = os.path.join(poly_folder, (area_name+\"_duplicate_hearth_prediction_polys.shp\"))\n","\n","batch_groups = ['0-597']\n","\n","for batch_group in batch_groups:\n","    print(batch_group)  \n","    pred_poly_folder = os.path.join(poly_folder, (batch_group + \"/\"))\n","    all_pred_points_df, dup_pred_polys_df, area_pred_points_df = preds_to_points(\"pa_forest_district_01_michaux\", pred_poly_folder, all_pred_points_df, dup_pred_polys_df, area_crs)\n","    area_points_outfp = os.path.join(poly_folder, (area_name+\"_\"+batch_group+\"_hearth_prediction_points.shp\"))\n","    # Write the data into that Shapefile\n","    if not area_pred_points_df.empty:    \n","        area_pred_points_df.to_file(area_points_outfp)\n","        print(\"Total points for area:\", len(area_pred_points_df))\n","\n","# Write the data into that Shapefile\n","if not all_pred_points_df.empty:    \n","    all_pred_points_df.to_file(all_points_outfp)\n","    print(\"Total points:\", len(all_pred_points_df))\n","if not dup_pred_polys_df.empty:\n","    dup_pred_polys_df.to_file(dup_polys_outfp)\n","    print(\"Total duplicate polys:\", len(dup_pred_polys_df))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"4_read_predictions_from_xml_put_into_shp_pa_forest_district_01.ipynb","provenance":[{"file_id":"1PVRwllaR5czZn-GQ5x9c3Vrfl9Y7VbSe","timestamp":1634996536014}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}